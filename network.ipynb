{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "-4eDAEf1g8E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop(encoder_layer: torch.Tensor, decoder_layer: torch.Tensor):\n",
        "    # Center-crops the encoder_layer to the size of the decoder_layer\n",
        "    # only necessary for input sizes != 2**n\n",
        "    # notice shape: batch-channel-height-width\n",
        "    \n",
        "    len_encoder = encoder_layer.shape[2]\n",
        "    len_decoder = decoder_layer.shape[2]\n",
        "    if len_encoder != len_decoder:\n",
        "      assert len_encoder >= len_decoder\n",
        "\n",
        "      cropped_encoder_layer = encoder_layer[\n",
        "          :, \n",
        "          :,\n",
        "          ((len_encoder - len_decoder) // 2):((len_encoder + len_decoder) // 2), \n",
        "          ((len_encoder - len_decoder) // 2):((len_encoder + len_decoder) // 2)]\n",
        "    else:\n",
        "      cropped_encoder_layer = encoder_layer\n",
        "\n",
        "    return cropped_encoder_layer"
      ],
      "metadata": {
        "id": "GNI4WcOqJxrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test crop\n",
        "def test_crop():\n",
        "  x = torch.randn(2, 128, 280, 200)\n",
        "  y = torch.randn(2, 128, 280, 200)\n",
        "  cropped_x = crop(x, y)\n",
        "  z = torch.cat([cropped_x, y], 1)\n",
        "\n",
        "  print(z.shape)\n",
        "  print(x.shape, cropped_x.shape, y.shape)\n",
        "  print(x.type())\n",
        "\n",
        "# test_crop()\n"
      ],
      "metadata": {
        "id": "4RrHfXldNDj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownBlock(nn.Module):\n",
        "  def __init__(self, in_, out, batchnorm=True):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels=in_, out_channels=out, kernel_size=4, stride=2, padding=1)\n",
        "    self.batchnorm = nn.BatchNorm2d(out)\n",
        "    self.leaky_relu = nn.LeakyReLU(0.2, True)\n",
        "\n",
        "    self.batchnorm_key = batchnorm\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv(x)\n",
        "    if self.batchnorm_key:\n",
        "      x = self.batchnorm(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "  def __init__(self, in_, out, batchnorm=True, dropout=False):\n",
        "    super().__init__()\n",
        "    self.conv_transpose = nn.ConvTranspose2d(in_channels=in_, out_channels=out, kernel_size=4, stride=2, padding=1)\n",
        "    self.batchnorm = nn.BatchNorm2d(out)\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    self.relu = nn.ReLU(True)\n",
        "    \n",
        "    self.batchnorm_key = batchnorm\n",
        "    self.dropout_key = dropout\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(x)\n",
        "    x = self.conv_transpose(x)\n",
        "    if self.batchnorm_key:\n",
        "      x = self.batchnorm(x)\n",
        "    if self.dropout_key:\n",
        "      self.dropout(x)\n",
        "    \n",
        "    return x"
      ],
      "metadata": {
        "id": "eYU17TO_TGTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "291e8ec0-940b-4ce5-b947-c87c90c300f5"
      },
      "outputs": [],
      "source": [
        "# generator: modified Unet\n",
        "\n",
        "class Unet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # in_-C64-C128-C256-C512-C512-C512-C512-C512\n",
        "    # self.down1 = DownBlock(3, 64, batchnorm=False)\n",
        "    self.down1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "    self.down2 = DownBlock(64, 128)\n",
        "    self.down3 = DownBlock(128, 256)\n",
        "    self.down4 = DownBlock(256, 512)\n",
        "    self.down5 = DownBlock(512, 512)\n",
        "    self.down6 = DownBlock(512, 512)\n",
        "    self.down7 = DownBlock(512, 512)\n",
        "    self.down8 = DownBlock(512, 512, batchnorm=False)\n",
        "\n",
        "    # in_-C512-C512-C512-C512-C256-C128-C64-C3\n",
        "    self.up1 = UpBlock(512, 512, dropout=True)\n",
        "    self.up2 = UpBlock(1024, 512, dropout=True)\n",
        "    self.up3 = UpBlock(1024, 512, dropout=True)\n",
        "    self.up4 = UpBlock(1024, 512)\n",
        "    self.up5 = UpBlock(1024, 256)\n",
        "    self.up6 = UpBlock(512, 128)\n",
        "    self.up7 = UpBlock(256, 64)\n",
        "    self.up8 = UpBlock(128, 3, batchnorm=False)\n",
        "\n",
        "    # last activation\n",
        "    self.tanh = nn.Tanh()\n",
        "\n",
        "\n",
        "  def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # downsampling\n",
        "    d1 = self.down1(x)\n",
        "    d2 = self.down2(d1)\n",
        "    d3 = self.down3(d2)\n",
        "    d4 = self.down4(d3)\n",
        "    d5 = self.down5(d4)\n",
        "    d6 = self.down6(d5)\n",
        "    d7 = self.down7(d6)\n",
        "    d8 = self.down8(d7)\n",
        "\n",
        "    # upsampling\n",
        "    u1 = self.up1(d8)\n",
        "    cropped_d7 = crop(d7, u1)\n",
        "    u1 = torch.cat([u1, cropped_d7], 1)\n",
        "\n",
        "    u2 = self.up2(u1)\n",
        "    cropped_d6 = crop(d6, u2)\n",
        "    u2 = torch.cat([u2, cropped_d6], 1)\n",
        "\n",
        "    u3 = self.up3(u2)\n",
        "    cropped_d5 = crop(d5, u3)\n",
        "    u3 = torch.cat([u3, cropped_d5], 1)\n",
        "\n",
        "    u4 = self.up4(u3)\n",
        "    cropped_d4 = crop(d4, u4)\n",
        "    u4 = torch.cat([u4, cropped_d4], 1)\n",
        "\n",
        "    u5 = self.up5(u4)\n",
        "    cropped_d3 = crop(d3, u5)\n",
        "    u5 = torch.cat([u5, cropped_d3], 1)\n",
        "\n",
        "    u6 = self.up6(u5)\n",
        "    cropped_d2 = crop(d2, u6)\n",
        "    u6 = torch.cat([u6, cropped_d2], 1)\n",
        "\n",
        "    u7 = self.up7(u6)\n",
        "    cropped_d1 = crop(d1, u7)\n",
        "    u7 = torch.cat([u7, cropped_d1], 1)\n",
        "\n",
        "    u8 = self.up8(u7)\n",
        "    \n",
        "\n",
        "    return self.tanh(u8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test Unet \n",
        "def test_Unet():\n",
        "  generator = Unet()\n",
        "  input = torch.randn(1, 3, 256, 256)\n",
        "  result = generator(input)\n",
        "  print(result.shape)\n",
        "\n",
        "# test_Unet()\n"
      ],
      "metadata": {
        "id": "ahlAQrGaY9M5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchGAN_70(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=6, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "    # self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=2, padding=1)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1)\n",
        "    self.batchnorm3 = nn.BatchNorm2d(256)\n",
        "    self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=1, padding=1)\n",
        "    self.batchnorm4 = nn.BatchNorm2d(512)\n",
        "    self.conv5 = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, stride=1, padding=1)\n",
        "\n",
        "    self.leaky_relu =  nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "            \n",
        "\n",
        "  def forward(self, input, target):\n",
        "    x = torch.cat([input, target], 1)\n",
        "    x = self.leaky_relu(self.conv1(x))\n",
        "    x = self.leaky_relu(self.batchnorm2(self.conv2(x)))\n",
        "    x = self.leaky_relu(self.batchnorm3(self.conv3(x)))\n",
        "    x = self.leaky_relu(self.batchnorm4(self.conv4(x)))\n",
        "    x = self.conv5(x)\n",
        "\n",
        "    return self.sigmoid(x)"
      ],
      "metadata": {
        "id": "Rbhqout4TInh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discriminator: 16x16 patchGAN\n",
        "\n",
        "class PatchGAN_16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=6, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "    # self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4, stride=1, padding=1)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=4, stride=1, padding=1)\n",
        "\n",
        "    self.leaky_relu =  nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "  \n",
        "\n",
        "  def forward(self, input, target):\n",
        "    x = torch.cat([input, target], 1)\n",
        "    x = self.conv1(x)\n",
        "    # x = self.batchnorm1(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.batchnorm2(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "MbT620RRkzRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discriminator: 1x1 pixelGAN\n",
        "\n",
        "class PixelGAN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=6, out_channels=64, kernel_size=1, stride=1, padding=0)\n",
        "    # self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "    self.leaky_relu =  nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1, stride=1, padding=0, bias=nn.InstanceNorm2d)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(in_channels=128, out_channels=1, kernel_size=1, stride=1, padding=0, bias=nn.InstanceNorm2d)\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "            \n",
        "\n",
        "  def forward(self, input, target):\n",
        "    x = torch.cat([input, target], 1)\n",
        "    x = self.conv1(x)\n",
        "    # x = self.batchnorm1(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.batchnorm2(x)\n",
        "    x = self.leaky_relu(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.sigmoid(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "F-BF8wYvLXUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test patchGAN\n",
        "\n",
        "def test_patchGAN():\n",
        "  G = Unet().cuda()\n",
        "  input = torch.randn(1, 3, 572, 572).cuda()\n",
        "  G_output = G(input)\n",
        "  print(G_output.shape)\n",
        "\n",
        "  D = PatchGAN_70().cuda()\n",
        "  D_output = D(G_output, torch.randn(1, 3, G_output.shape[2], G_output.shape[2]).cuda())\n",
        "  print(D_output.shape)\n",
        "\n",
        "  D_output_1 = D(torch.randn(1, 3, 256, 256).cuda(), torch.randn(1, 3, 256, 256).cuda())\n",
        "  print(D_output_1.shape)\n",
        "\n",
        "# test_patchGAN()"
      ],
      "metadata": {
        "id": "MkuGLZTv0Y9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "metadata": {
        "id": "l4Oc3-_cs7XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zGveuTEz7DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QwP4Gh4lXPC"
      },
      "outputs": [],
      "source": [
        "# original Unet\n",
        "\n",
        "class Block_original(nn.Module):\n",
        "  def __init__(self, in_, middle, out, key):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=in_, out_channels=out, kernel_size=3)\n",
        "    self.conv2 = nn.Conv2d(in_channels=out, out_channels=out, kernel_size=3)\n",
        "    self.batchnorm = nn.BatchNorm2d(out)\n",
        "    self.activation = nn.ReLU()\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.batchnorm(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.batchnorm(x)\n",
        "    x = self.activation(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class Unet_original(nn.Module):\n",
        "  def __init__(self, in_):\n",
        "    super().__init__()\n",
        "    self.max_pooling = nn.MaxPool2d(2, 2)\n",
        "    # debug: stride=2\n",
        "    self.conv_transpose1 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)\n",
        "    self.conv_transpose2 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
        "    self.conv_transpose3 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
        "    self.conv_transpose4 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
        "\n",
        "    self.down_block1 = Block_original(in_, 64)\n",
        "    self.down_block2 = Block_original(64, 128)\n",
        "    self.down_block3 = Block_original(128, 256)\n",
        "    self.down_block4 = Block_original(256, 512)\n",
        "\n",
        "    self.up_block1 = Block_original(512, 1024)\n",
        "    self.up_block2 = Block_original(1024, 512)\n",
        "    self.up_block3 = Block_original(512, 256)\n",
        "    self.up_block4 = Block_original(256, 128)\n",
        "\n",
        "    self.last_block = Block_original(128, 64)\n",
        "    # out_channels=3 \n",
        "    self.last_conv = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # downsampling\n",
        "    # b1 - b4 are for skip connection\n",
        "    b1 = self.down_block1(x)\n",
        "    down_block1 = self.max_pooling(b1)\n",
        "    b2 = self.down_block2(down_block1)\n",
        "    down_block2 = self.max_pooling(b2)\n",
        "    b3 = self.down_block3(down_block2)\n",
        "    down_block3 = self.max_pooling(b3)\n",
        "    b4 = self.down_block4(down_block3)\n",
        "    down_block4 = self.max_pooling(b4)\n",
        "\n",
        "    # upsampling\n",
        "    u1 = self.up_block1(down_block4)\n",
        "    up_block1 = self.conv_transpose1(u1)\n",
        "    cropped_b4 = crop(b4, up_block1)\n",
        "    skip_connect1 = torch.cat([cropped_b4, up_block1], 1)\n",
        "\n",
        "    u2 = self.up_block2(skip_connect1)\n",
        "    up_block2 = self.conv_transpose2(u2)\n",
        "    cropped_b3 = crop(b3, up_block2)\n",
        "    skip_connect2 = torch.cat([cropped_b3, up_block2], 1)\n",
        "\n",
        "    u3 = self.up_block3(skip_connect2)\n",
        "    up_block3 = self.conv_transpose3(u3)\n",
        "    cropped_b2 = crop(b2, up_block3)\n",
        "    skip_connect3 = torch.cat([cropped_b2, up_block3], 1)\n",
        "\n",
        "    u4 = self.up_block4(skip_connect3)\n",
        "    up_block4 = self.conv_transpose4(u4)\n",
        "    cropped_b1 = crop(b1, up_block4)\n",
        "    skip_connect4 = torch.cat([cropped_b1, up_block4], 1)\n",
        "\n",
        "    # last convolution\n",
        "    last = self.last_block(skip_connect4)\n",
        "    result = self.last_conv(last)\n",
        "\n",
        "    return result"
      ]
    }
  ]
}