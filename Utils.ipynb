{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from torchvision import datasets\n",
        "import pathlib\n",
        "import torch\n",
        "#from scipy.misc import imresize\n",
        "#from PIL import Image\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import itertools\n",
        "import imageio\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "YFjWLiOGiJah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiHrlA__gRvy"
      },
      "outputs": [],
      "source": [
        "def get_data(data_key):\n",
        "  #data key can be a number or the name of the data set\n",
        "  #0:facades\n",
        "  #1:maps\n",
        "  #2: edges to shoes\n",
        "\n",
        "  # downlodeading the data_set\n",
        "  if data_key == 0: data_key = 'facades'\n",
        "  if data_key == 1: data_key = 'maps'\n",
        "  if data_key == 2: data_key = 'edges2shoes'\n",
        "\n",
        "  _URL = f'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/{data_key}.tar.gz'\n",
        "  path_to = tf.keras.utils.get_file(fname=f\"{data_key}.tar.gz\", origin=_URL, extract=True)\n",
        "  path_to  = pathlib.Path(path_to)\n",
        "  path = path_to.parent/data_key\n",
        "  #print(path)\n",
        "\n",
        "  return path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_key):\n",
        "  #getting the data\n",
        "  path = get_data(data_key)\n",
        "  transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
        "  d_set = datasets.ImageFolder(path, transform) \n",
        "  d_set2 = datasets.ImageFolder(path, transform)\n",
        "  ind_train = d_set.class_to_idx['train']\n",
        "  #ind_test = d_set2.class_to_idx['test']\n",
        "\n",
        "  #splitting into test and training set\n",
        "  n = 0\n",
        "  m = 0\n",
        "  for i in range(d_set.__len__()):\n",
        "    if ind_train != d_set.imgs[n][1]:\n",
        "      del d_set.imgs[n]\n",
        "      n -= 1\n",
        "    else: \n",
        "      del d_set2.imgs[m]\n",
        "      m -= 1\n",
        "    n += 1\n",
        "    m += 1\n",
        "  \n",
        "  \n",
        "  train_load = torch.utils.data.DataLoader(d_set, 1, shuffle=True)\n",
        "  test_load = torch.utils.data.DataLoader(d_set2, 1, shuffle=True)\n",
        "\n",
        "  return train_load, test_load\n",
        "  "
      ],
      "metadata": {
        "id": "vhVO1Ue7j3I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_load, test_load = load_data(0)\n",
        "n= 0\n",
        "m= 0\n",
        "for x,_ in train_load:\n",
        "  n+=1\n",
        "for y,_ in test_load:\n",
        "  m+=1\n",
        "print('n: ',n)\n",
        "print('m: ', m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikNi2-OVaG0f",
        "outputId": "0047172f-c703-4701-b497-5711ac1d3385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
            "30171136/30168306 [==============================] - 20s 1us/step\n",
            "30179328/30168306 [==============================] - 20s 1us/step\n",
            "n:  400\n",
            "m:  206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "def prepare_image(x_,size=256,order = True,crop= True):\n",
        "#works for facades, for maps size needs to be 600 for eges2shoes order and crop needs to be false\n",
        "\n",
        "  if order:\n",
        "    y_ = x_[:, :, :, 0:size]\n",
        "    x_ = x_[:, :, :, size:]\n",
        "  else:\n",
        "    y_ = x_[:, :, :, size:]\n",
        "    x_ = x_[:, :, :, 0:size]\n",
        "\n",
        "  #resize if size = 256\n",
        "  if size == 256 and crop:\n",
        "    output_x = torch.FloatTensor(1, 3, 286, 286)\n",
        "    output_y = torch.FloatTensor(1, 3, 286, 286)\n",
        "    resizer = transforms.Resize(286)\n",
        "    x_ = resizer(x_)\n",
        "    y_ = resizer(y_)\n",
        "\n",
        "  #random crop\n",
        "  if crop:\n",
        "    cur_size = x_.size()[2]\n",
        "    output_x = torch.FloatTensor(1, 3, 256, 256)\n",
        "    output_y = torch.FloatTensor(1, 3, 256, 256)\n",
        "    rand1 = np.random.randint(0, cur_size - 256)\n",
        "    rand2 = np.random.randint(0, cur_size - 256)\n",
        "    output_x = x_[:,:, rand1: 256 + rand1, rand2: 256 + rand2]\n",
        "    output_y = y_[:,:, rand1: 256 + rand1, rand2: 256 + rand2]\n",
        "    x_ = output_x\n",
        "    y_ = output_y\n",
        "      \n",
        "  #flip ocassionally\n",
        "  if torch.rand(1)[0] < 0.3:\n",
        "    #print('flip')\n",
        "    #print(x_)\n",
        "    #print(y_)\n",
        "    outputs_x = torch.FloatTensor(x_.size())\n",
        "    outputs_y = torch.FloatTensor(x_.size())\n",
        "    #for i in range(256):\n",
        "    img_x = torch.FloatTensor((np.fliplr(x_[0].numpy().transpose(1, 2, 0)).transpose(2, 0, 1).reshape(-1, 3, 256, 256) + 1) / 2)\n",
        "    outputs_x[0] = (img_x - 0.5) / 0.5\n",
        "    img_y = torch.FloatTensor((np.fliplr(y_[0].numpy().transpose(1, 2, 0)).transpose(2, 0, 1).reshape(-1, 3, 256, 256) + 1) / 2)\n",
        "    outputs_y[0] = (img_y - 0.5) / 0.5\n",
        "  \n",
        "    x_ = outputs_x\n",
        "    y_ = outputs_y\n",
        "    #print(x_)\n",
        "    #print(y_)\n",
        "\n",
        "  return x_, y_\n",
        "\n"
      ],
      "metadata": {
        "id": "m8_tmm2nwTlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_prepare_image():\n",
        "  training, testing = load_data(0)\n",
        "  for x,_ in training:\n",
        "    xp,yp = prepare_image(x)\n",
        "    print(xp.type()) \n"
      ],
      "metadata": {
        "id": "oYn0cK99tubD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_picture(G,x_,y_,epoch,path): \n",
        "  #creates an image with the current model\n",
        "  cr_im = G(x_)\n",
        "  size_figure_grid = 3\n",
        "  fig, ax = plt.subplots(x_.size()[0], size_figure_grid, figsize=(5, 5))\n",
        "  y_ = y_.cpu()\n",
        "\n",
        "  ax[0].imshow((x_[0].cpu().data.numpy().transpose(1, 2, 0) + 1) / 2)\n",
        "  ax[1].imshow((cr_im[0].cpu().data.numpy().transpose(1, 2, 0) + 1) / 2)\n",
        "  ax[2].imshow((y_[0].numpy().transpose(1, 2, 0) + 1) / 2)\n",
        "\n",
        "  label = 'Epoch {0}'.format(epoch)\n",
        "  plt.savefig(path)\n",
        "  plt.close()\n"
      ],
      "metadata": {
        "id": "fqmwK5xR9BlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(history, root, model, epoch,loss_key):\n",
        "  images = []\n",
        "  for e in range(epoch):\n",
        "    img_name = root + 'Fixed_results/loss_key'+str(loss_key)+'/' + model  + str(epoch + 1) + '.png'\n",
        "    images.append(imageio.imread(img_name))\n",
        "  imageio.mimsave(root + model+ str(loss_key) + 'generate_animation.gif', images, fps=2)\n",
        "\n",
        "  x = range(len(history['D_losses']))\n",
        "  y1 = history['D_losses']\n",
        "  y2 = history['G_losses']\n",
        "\n",
        "  plt.plot(x, y1, label='D_loss')\n",
        "  plt.plot(x, y2, label='G_loss')\n",
        "  plt.xlabel('Iteration')\n",
        "  plt.ylabel('Losses')\n",
        "\n",
        "  plt.legend(loc=4)\n",
        "  plt.grid(True)\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(root + model + 'train_hist.png')\n",
        "  plt.close()\n"
      ],
      "metadata": {
        "id": "ixEZM2T28hUf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}